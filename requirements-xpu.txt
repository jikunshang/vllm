cmake>=3.21
ninja  # For faster builds.
psutil
ray >= 2.9
sentencepiece  # Required for LLaMA tokenizer.
numpy

torch @ https://ubit-artifactory-sh.intel.com/artifactory/aipc_releases-sh-local/gpu-new/validation/IPEX/weekly/PVC/2024/ww13/py39/torch-2.1.0a0+gitc61d29a-cp39-cp39-linux_x86_64.whl
# intel_extension_for_pytorch @ https://ubit-artifactory-sh.intel.com/artifactory/aipc_releases-sh-local/gpu-new/validation/IPEX/weekly/PVC/2024/ww13/py39/intel_extension_for_pytorch-2.1.30+gitcdec5e9-cp39-cp39-linux_x86_64.whl
oneccl_bind_pt @ https://ubit-artifactory-sh.intel.com/artifactory/aipc_releases-sh-local/gpu-new/validation/IPEX/weekly/PVC/2024/ww13/py39/oneccl_bind_pt-2.1.0+gpu-cp39-cp39-linux_x86_64.whl
# torch @ https://intel-extension-for-pytorch.s3.amazonaws.com/ipex_stable/xpu/torch-2.1.0a0%2Bcxx11.abi-cp310-cp310-linux_x86_64.whl
# intel_extension_for_pytorch @ https://intel-extension-for-pytorch.s3.amazonaws.com/ipex_stable/xpu/intel_extension_for_pytorch-2.1.10%2Bxpu-cp310-cp310-linux_x86_64.whl
# oneccl_bind_pt @ https://intel-extension-for-pytorch.s3.amazonaws.com/ipex_stable/xpu/oneccl_bind_pt-2.1.100%2Bxpu-cp310-cp310-linux_x86_64.whl  
#torch == 2.1.0a0+cxx11.abi
#intel_extension_for_pytorch == 2.1.10+xpu
#oneccl_bind_pt == 2.1.100+xpu

transformers >= 4.39.1  # Required for StarCoder2 & Llava.
fastapi == 0.109.0
uvicorn[standard]
pydantic >= 2.0  # Required for OpenAI server.
prometheus_client >= 0.18.0
pynvml == 11.5.0
# outlines == 0.0.34

#triton @ https://github.com/intel/intel-xpu-backend-for-triton/releases/download/v2.1.0/triton-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
# triton @ https://github.com/intel/intel-xpu-backend-for-triton/releases/download/v2.1.0/triton-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl

wheel
einops  # Required for phi-1_5
